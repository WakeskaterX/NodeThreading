{
  "name": "loadtest",
  "version": "1.2.4",
  "description": "Run load tests for your web application. Mostly ab-compatible interface, with an option to force requests per second. Includes an API for automated load testing.",
  "homepage": "https://github.com/alexfernandez/loadtest",
  "contributors": [
    {
      "name": "Alex Fernández",
      "email": "alexfernandeznpm@gmail.com"
    }
  ],
  "license": "MIT",
  "main": "index.js",
  "repository": {
    "type": "git",
    "url": "https://github.com/alexfernandez/loadtest"
  },
  "dependencies": {
    "prototypes": "*",
    "agentkeepalive": "0.1.*",
    "log": "1.4.*",
    "stdio": "^0.2.3",
    "testing": "*"
  },
  "keywords": [
    "testing",
    "test",
    "load test",
    "load testing",
    "http",
    "performance",
    "black box"
  ],
  "engines": {
    "node": ">=0.10.3"
  },
  "bin": {
    "loadtest": "bin/loadtest.js",
    "testserver-loadtest": "bin/testserver.js"
  },
  "preferGlobal": true,
  "scripts": {
    "test": "node test.js"
  },
  "private": false,
  "readme": "[![Build Status](https://secure.travis-ci.org/alexfernandez/loadtest.png)](http://travis-ci.org/alexfernandez/loadtest)\n\n# loadtest\n\nRuns a load test on the selected HTTP URL. The API allows for easy integration in your own tests.\n\n## Installation\n\nInstall globally as root:\n\n    # npm install -g loadtest\n\nOn Ubuntu or Mac OS X systems install using sudo:\n\n    $ sudo npm install -g loadtest\n\nFor access to the API just add package `loadtest` to your `package.json` devDependencies:\n\n    {\n        ...\n        \"devDependencies\": {\n            \"loadtest\": \"*\"\n        },\n        ...\n    }\n\n## Change Log\n\nLatest significant changes.\n\n### Changes in version 1.2\n\n* Option `--keepalive` can now be used as `-k`.\n\n### Changes in Version 1.1\n\n* Mechanism to generate different POST and PUT bodies using a function.\n* Duplicate headers are now ignored; set them using `-H header:value1;value2`.\n\n### Changes in Version 1.0\n\n* Option parsing has been improved; no longer is a `true` needed after certain options.\n* Requests per second specified with `--rps` are now total rps, instead of multiplied by concurrency.\n* Option `--agent` has been deprecated in favor of `--keepalive`.\n* Support for Node.js < 0.10 removed.\n\n## Usage\n\nWhy use `loadtest` instead of any other of the available tools, notably Apache `ab`?\n`loadtest` allows you to configure and tweak requests to simulate real world loads.\n\n### Basic Usage\n\nRun as a script to load test a URL:\n\n    $ loadtest [-n requests] [-c concurrency] [-k] URL\n\nThe URL can be \"http://\" or \"https://\".\nSet the max number of requests with `-n`, and the desired level of concurrency with the `-c` parameter.\nUse keep-alive connections with `-k` whenever it makes sense,\nwhich should be always except when you are testing opening and closing connections.\n\nSingle-dash parameters (e.g. `-n`) are designed to be compatible with\n[Apache `ab`](http://httpd.apache.org/docs/2.2/programs/ab.html),\nexcept that here you can add the parameters _after_ the URL.\n\nTo get online help, run loadtest without parameters:\n\n    $ loadtest\n\n### Usage Dos\n\nThe set of basic options are designed to be compatible with Apache `ab`.\nBut while `ab` can only set a concurrency level and lets the server adjust to it,\n`loadtest` allows you to set a rate or requests per second with the `--rps` option.\nExample:\n\n    loadtest -c 10 --rps 200 http://mysite.com/\n\nThis command sends exactly 200 requests per second with concurrency 10,\nso you can see how your server copes with sustained rps.\nEven if `ab` reported a rate of 200 rps,\nyou will be surprised to see how a constant rate of requests per second affects performance:\nno longer are the requests adjusted to the server, but the server must adjust to the requests!\nRps rates are usually lowered dramatically, at least 20~25% (in our example from 200 to 150 rps),\nbut the resulting figure is much more robust.\n\n`loadtest` is also quite extensible.\nUsing the provided API it is very easy to integrate loadtest with your package, and run programmatic load tests.\nloadtest makes it very easy to run load tests as part of systems tests, before deploying a new version of your software.\nThe results include mean response times and percentiles,\nso that you can abort deployment e.g. if 99% of the requests don't finish in 10 ms or less.\n\n### Usage Don'ts\n\n`loadtest` saturates a single CPU pretty quickly.\nDo not use `loadtest` if the Node.js process is above 100% usage in `top`, which happens approx. when your load is above ~4000 rps.\n(You can measure the practical limits of `loadtest` on your specific test machines by running it against a simple\nApache or nginx process and seeing when it reaches 100% CPU.)\n\nThere are better tools for that use case:\n\n* [Apache `ab`](http://httpd.apache.org/docs/2.2/programs/ab.html)\nhas great performance, but it is also limited by a single CPU performance.\nIts practical limit is somewhere around ~40 krps.\n* [weighttp](http://redmine.lighttpd.net/projects/weighttp/wiki) is also `ab`-compatible\nand is supposed to be very fast (the author has not personally used it).\n* [wrk](https://github.com/wg/wrk) is multithreaded and fit for use when multiple CPUs are required or available.\nIt may need installing from source though, and its interface is not `ab`-compatible.\n\n### Regular Usage\n\nThe following parameters are compatible with Apache ab.\n\n#### `-n requests`\n\nNumber of requests to send out.\n\nNote: the total number of requests sent can be bigger than the parameter, if there is a concurrency parameter\nand number of requests is not a multiple of concurrency.\n\n#### `-c concurrency`\n\nloadtest will create a simultaneous number of clients; this parameter controls how many.\n\n#### `-t timelimit`\n\nMax number of seconds to wait until requests no longer go out.\n\nNote: this is different than Apache `ab`, which stops _receiving_ requests after the given seconds.\n\n#### `-k` or `--keepalive`\n\nOpen connections using keep-alive: use header 'Connection: Keep-alive' instead of 'Connection: Close'.\n\nNote: Uses [agentkeepalive](https://npmjs.org/package/agentkeepalive),\nwhich performs better than the default node.js agent.\n\n#### `-C cookie-name=value`\n\nSend a cookie with the request. The cookie `name=value` is then sent to the server.\nThis parameter can be repeated as many times as needed.\n\n#### `-H header:value`\n\nSend a custom header with the request. The line `header:value` is then sent to the server.\nThis parameter can be repeated as many times as needed.\nExample:\n\n    $ loadtest -H user-agent:tester/0.4 ...\n\nNote: if not present, loadtest will add a few headers on its own: the \"host\" header parsed from the URL,\na custom user agent \"loadtest/\" plus version (`loadtest/1.1.0`), and an accept header for \"\\*/\\*\".\n\nNote: when the same header is sent several times, only the last value will be considered.\nIf you want to send multiple values with a header, separate them with semicolons:\n\n    $ loadtest -H accept:text/plain;text-html ...\n\n#### `-T content-type`\n\nSet the MIME content type for POST data. Default: `text/plain`.\n\n#### `-P POST-body`\n\nSend the string as the POST body. E.g.: `-P '{\"key\": \"a9acf03f\"}'`\n\n#### `-p POST-file`\n\nSend the data contained in the given file in the POST body.\nRemember to set `-T` to the correct content-type.\n\nIf `POST-file` has `.js` extension it will be `require`d. It should be a valid node module and it\nshould `export` a single function, which is invoked with an automatically generated request identifier\nto provide the body of each request.\nThis is useful if you want to generate request bodies dynamically and vary them for each request.\n\nExample:\n\n    module.exports = function(requestId) {\n      // this object will be serialized to JSON and sent in the body of the request\n      return {\n        key: 'value',\n        requestId: requestId\n      };\n    };\n\n#### `-u PUT-file`\n\nSend the data contained in the given file as a PUT request.\nRemember to set `-T` to the correct content-type.\n\nIf `PUT-file` has `.js` extension it will be `require`d. It should be a valid node module and it\nshould `export` a single function, which is invoked with an automatically generated request identifier\nto provide the body of each request.\nThis is useful if you want to generate request bodies dynamically and vary them for each request.\nFor an example function see above for `-p`.\n\n##### `-r`\n\nRecover from errors. Always active: loadtest does not stop on errors.\nAfter the tests are finished, if there were errors a report with all error codes will be shown.\n\n#### `-V`\n\nShow version number and exit.\n\n### Advanced Usage\n\nThe following parameters are _not_ compatible with Apache ab.\n\n#### `--rps requestsPerSecond`\n\nControls the number of requests per second that are sent.\nCan be fractional, e.g. `--rps 0.5` sends one request every two seconds.\n\nNote: Concurrency doesn't affect the final number of requests per second,\nsince rps will be shared by all the clients. E.g.:\n\n    loadtest <url> -c 10 --rps 10\n\nwill send a total of 10 rps to the given URL, from 10 different clients\n(each client will send 1 request per second).\n\nBeware: if concurrency is too low then it is possible that there will not be enough clients\nto send all of the rps, adjust it with `-c` if needed.\n\n#### `--timeout milliseconds`\n\nTimeout for each generated request in milliseconds.\nDefault value provided by Node.js client is 3000.\nSetting this to 0 disables timeout.\n\n#### `-R requestGeneratorModule.js`\n\nUse custom request generator function from an external file.\n\nExample request generator module could look like this:\n\n```javascript\nmodule.exports = function(params, options, client, callback) {\n  generateMessageAsync(function(message)) {\n    request = client(options, callback);\n\n    if (message)\n    {\n      options.headers['Content-Length'] = message.length;\n      options.headers['Content-Type'] = 'application/x-www-form-urlencoded';\n      request.write(message);\n    }\n\n    request.end();\n  }\n}\n```\n\n#### `--agent` (deprecated)\n\nOpen connections using keep-alive.\n\nNote: instead of using the default agent, this option is now an alias for `-k`.\n\n#### `--quiet`\n\nDo not show any messages.\n\n#### `--debug`\n\nShow debug messages.\n\n#### `--insecure`\n\nAllow invalid and self-signed certificates over https.\n\n### Server\n\nloadtest bundles a test server. To run it:\n\n    $ testserver [--delay ms] [error 5xx] [percent yy] [port]\n\nThis command will show the number of requests received per second,\nthe latency in answering requests and the headers for selected requests.\n\nThe server returns a short text 'OK' for every request,\nso that latency measurements don't have to take into account request processing.\n\nIf no port is given then default port 7357 will be used.\nThe optional delay instructs the server to wait for the given number of milliseconds\nbefore answering each request, to simulate a busy server.\nYou can also simulate errors on a given percent of requests.\n\n### Complete Example\n\nLet us now see how to measure the performance of the test server.\n\nFirst we install `loadtest` globally:\n\n    $ sudo npm install -g loadtest\n\nNow we start the test server:\n\n    $ testserver\n    Listening on port 7357\n\nOn a different console window we run a load test against it for 20 seconds\nwith concurrency 10 (only relevant results are shown):\n\n    $ loadtest http://localhost:7357/ -t 20 -c 10\n    ...\n    Requests: 9589, requests per second: 1915, mean latency: 10 ms\n    Requests: 16375, requests per second: 1359, mean latency: 10 ms\n    Requests: 16375, requests per second: 0, mean latency: 0 ms\n    ...\n    Completed requests:  16376\n    Requests per second: 368\n    Total time:          44.503181166000005 s\n\n    Percentage of the requests served within a certain time\n      50%      4 ms\n      90%      5 ms\n      95%      6 ms\n      99%      14 ms\n     100%      35997 ms (longest request)\n\nResults were quite erratic, with some requests taking up to 36 seconds;\nthis suggests that Node.js is queueing some requests for a long time, and answering them irregularly.\nNow we will try a fixed rate of 1000 rps:\n\n    $ loadtest http://localhost:7357/ -t 20 -c 10 --rps 1000\n    ...\n    Requests: 4551, requests per second: 910, mean latency: 0 ms\n    Requests: 9546, requests per second: 1000, mean latency: 0 ms\n    Requests: 14549, requests per second: 1000, mean latency: 20 ms\n    ...\n    Percentage of the requests served within a certain time\n      50%      1 ms\n      90%      2 ms\n      95%      8 ms\n      99%      133 ms\n     100%      1246 ms (longest request)\n\nAgain erratic results. In fact if we leave the test running for 50 seconds we start seeing errors:\n\n    $ loadtest http://localhost:7357/ -t 50 -c 10 --rps 1000\n    ...\n    Requests: 29212, requests per second: 496, mean latency: 14500 ms\n    Errors: 426, accumulated errors: 428, 1.5% of total requests\n\nLet us lower the rate to 500 rps:\n\n    $ loadtest http://localhost:7357/ -t 20 -c 10 --rps 5000\n    ...\n    Requests: 0, requests per second: 0, mean latency: 0 ms\n    Requests: 2258, requests per second: 452, mean latency: 0 ms\n    Requests: 4757, requests per second: 500, mean latency: 0 ms\n    Requests: 7258, requests per second: 500, mean latency: 0 ms\n    Requests: 9757, requests per second: 500, mean latency: 0 ms\n    ...\n    Requests per second: 500\n    Completed requests:  9758\n    Total errors:        0\n    Total time:          20.002735398000002 s\n    Requests per second: 488\n    Total time:          20.002735398000002 s\n\n    Percentage of the requests served within a certain time\n      50%      1 ms\n      90%      1 ms\n      95%      1 ms\n      99%      14 ms\n     100%      148 ms (longest request)\n\nMuch better: a sustained rate of 500 rps is seen most of the time,\n488 rps average, and 99% of requests answered within 14 ms.\n\nWe now know that our server can accept 500 rps without problems.\nNot bad for a single-process naïve Node.js server...\nWe may refine our results further to find at which point from 500 to 1000 rps our server breaks down.\n\nBut instead let us research how to improve the results.\nOne obvious candidate is to add keep-alive to the requests so we don't have to create\na new connection for every request.\nThe results (with the same test server) are impressive:\n\n    $ loadtest http://localhost:7357/ -t 20 -c 10 -k\n    ...\n    Requests per second: 4099\n\n    Percentage of the requests served within a certain time\n    50%      2 ms\n    90%      3 ms\n    95%      3 ms\n    99%      10 ms\n    100%      25 ms (longest request)\n\nNow you're talking! The steady rate also goes up to 2 krps:\n\n    $ loadtest http://localhost:7357/ -t 20 -c 10 --keepali --rps 2000\n    ...\n    Requests per second: 1950\n\n    Percentage of the requests served within a certain time\n      50%      1 ms\n      90%      2 ms\n      95%      2 ms\n      99%      7 ms\n     100%      20 ms (longest request)\n\nNot bad at all: 2 krps with a single core, sustained.\nHowever, it you try to push it beyond that, at 3 krps it will fail miserably.\n\n## API\n\n`loadtest` is not limited to running from the command line; it can be controlled using an API,\nthus allowing you to load test your application in your own tests.\n\n### Invoke Load Test\n\nTo run a load test, just call the exported function `loadTest()` with a set of options and an optional callback:\n\n    var loadtest = require('loadtest');\n    var options = {\n        url: 'http://localhost:8000',\n        maxRequests: 1000,\n    };\n    loadtest.loadTest(options, function(error, result)\n    {\n        if (error)\n        {\n            return console.error('Got an error: %s', error);\n        }\n        console.log('Tests run successfully');\n    });\n\nThe callback `function(error, result)` will be invoked when the max number of requests is reached,\nor when the max number of seconds has elapsed.\n\nBeware: if there are no `maxRequests` and no `maxSeconds`, then tests will run forever\nand will not call the callback.\n\n### Options\n\nAll options but `url` are, as their name implies, optional.\n\n#### `url`\n\nThe URL to invoke. Mandatory.\n\n#### `concurrency`\n\nHow many clients to start in parallel.\n\n#### `maxRequests`\n\nA max number of requests; after they are reached the test will end.\n\n#### `maxSeconds`\n\nMax number of seconds to run the tests.\n\nNote: after the given number of seconds `loadtest` will stop sending requests,\nbut may continue receiving tests afterwards.\n\n#### `timeout`\n\nTimeout for each generated request in milliseconds. Default value provided by Node.js client is 3000. Setting this to 0 disables timeout.\n\n#### `cookies`\n\nAn array of cookies to send. Each cookie should be a string of the form name=value.\n\n#### `headers`\n\nA map of headers. Each header should be an entry in the map with the value given as a string.\nIf you want to have several values for a header, write a single value separated by semicolons,\nlike this:\n\n    {\n        accept: \"text/plain;text/html\"\n    }\n\nNote: when using the API, the \"host\" header is not inferred from the URL but needs to be sent\nexplicitly.\n\n#### `method`\n\nThe method to use: POST, PUT. Default: GET.\n\n#### `body`\n\nThe contents to send in the body of the message, for POST or PUT requests.\nCan be a string or an object (which will be converted to JSON).\n\n#### `contentType`\n\nThe MIME type to use for the body. Default content type is `text/plain`.\n\n#### `requestsPerSecond`\n\nHow many requests each client will send per second.\n\n#### `requestGenerator`\n\nCustom request generator function.\n\nExample request generator function could look like this:\n\n```javascript\nfunction(params, options, client, callback) {\n  generateMessageAsync(function(message)) {\n    request = client(options, callback);\n\n    if (message)\n    {\n      options.headers['Content-Length'] = message.length;\n      options.headers['Content-Type'] = 'application/x-www-form-urlencoded';\n      request.write(message);\n    }\n\n    request.end();\n  }\n}\n```\n\n#### `agentKeepAlive`\n\nUse an agent with 'Connection: Keep-alive'.\n\nNote: Uses [agentkeepalive](https://npmjs.org/package/agentkeepalive),\nwhich performs better than the default node.js agent.\n\n#### `quiet`\n\nDo not show any messages.\n\n#### `indexParam`\n\nThe given string will be replaced in the final URL with a unique index.\nE.g.: if URL is `http://test.com/value` and `indexParam=value`, then the URL\nwill be:\n* http://test.com/1\n* http://test.com/2\n* ...\n\n#### `insecure`\n\nAllow invalid and self-signed certificates over https.\n\n### Results\n\nThe results passed to your callback at the end of the load test contains a full set of data, including:\nmean latency, number of errors and percentiles.\nAn example follows:\n\n    {\n      totalRequests: 1000,\n      percentiles: {\n        '50': 7,\n        '90': 10,\n        '95': 11,\n        '99': 15\n      },\n      rps: 2824,\n      totalTimeSeconds: 0.354108,\n      meanLatencyMs: 7.72,\n      totalErrors: 3,\n      errors: {\n        '0': 1,\n        '500': 2\n      }\n    }\n\n### Start Test Server\n\nTo start the test server use the exported function `startServer()` with a set of options and an optional callback:\n\n    var testserver = require('testserver');\n    var server = testserver.startServer({ port: 8000 });\n\nThis function returns an HTTP server which can be `close()`d when it is no longer useful.\n\nThe following options are available.\n\n#### `port`\n\nOptional port to use for the server.\n\nNote: the default port is 7357, since port 80 requires special privileges.\n\n#### `delay`\n\nWait the given number of milliseconds to answer each request.\n\n#### `error`\n\nReturn an HTTP error code.\n\n#### `percent`\n\nReturn an HTTP error code only for the given % of requests.\nIf no error code was specified, default is 500.\n\n### Complete Example\n\nThe file `lib/sample.js` shows a complete example, which is also a full integration test:\nit starts the server, send 1000 requests, waits for the callback and closes down the server.\n\n## License\n\n(The MIT License)\n\nCopyright (c) 2013-4 Alex Fernández <alexfernandeznpm@gmail.com>\nand [contributors](https://github.com/alexfernandez/loadtest/graphs/contributors).\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n",
  "readmeFilename": "README.md",
  "bugs": {
    "url": "https://github.com/alexfernandez/loadtest/issues"
  },
  "_id": "loadtest@1.2.4",
  "dist": {
    "shasum": "29ae49422e3fd09d7fd253f4da62f6db470a0b9b"
  },
  "_from": "loadtest@",
  "_resolved": "https://registry.npmjs.org/loadtest/-/loadtest-1.2.4.tgz"
}
